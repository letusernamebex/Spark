Potential interview questions:
1. What is partitioning in Spark?
2. What is bucketing in Spark?
3. Why both are needed?
4. When to use partitioning?
5. When to use bucketing?

Partitioning: Using partitionBy()

df.write.format("CSV")\
        .option("header","true")\
        .option("mode","overwrite")\
        .option("path",".....")\
        .partitionBy("col_to_partition")\
        .save()

df.write.format("CSV")\
        .option("header","true")\
        .option("mode","overwrite")\
        .option("path",".....")\
        .partitionBy("col1_to_partition","col2_to_partition")\
        .save()

df.write.format("CSV")\
        .option("header","true")\
        .option("mode","overwrite")\
        .option("path",".....")\
        .bucketBy(no_of_buckets,"col_to_bucket")\
        .saveAsTable("table_name")             #save throws error as it's not supported


